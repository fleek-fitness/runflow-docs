---
title: "WebsiteScraper"
description: "웹사이트의 콘텐츠를 자동으로 스크래핑하는 노드"
---
### Node Input

- `url` (string or string[]): The URL of the website to be scraped. Can be a single URL or provided as a list of URLs.

### Node Output

- `content` (string or string[]): The content collected from the website. It will be returned as a single string or a list of strings.

### Functionality

The WebsiteScraper node automatically scrapes content from the website at the specified URL(s). This allows users to gather and utilize the website's text content for various purposes. It employs AI-based scraping tools and strategies to collect and deliver data.

### When to Use?

The WebsiteScraper node is particularly useful in situations such as:

- When you need to collect the contents of specific web pages like news articles, product information, or blog posts
- When large-scale data collection or routine web content scraping is required
- When your workflow demands automated web crawling

### Examples

1. Automatically gather blog post content and store it in a database
2. Crawl product descriptions from a particular website for market research purposes
3. Automatically collect the latest articles from a news site for summarization tasks