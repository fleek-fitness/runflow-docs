---
title: "LLMCaller"
description: "A node that interacts with AI to generate responses"
---

### Node Input

- `prompt` (string or string[]): The main message to be sent to the AI. This can be a single text input or a list of texts, serving as the specific question or command you want the AI to address.
- `context` (string or string[]): Provides additional background information to help the AI understand the situation for a more relevant response. It can also be a single text input or a list.

### Node Output

- `response` (string or string[]): The AI-generated response based on the given `prompt`. This output matches the input prompt structure, providing a specific answer or response.

### Function

The LLMCaller node connects to an AI model using the input prompt and context to generate an AI response. The node ensures the model receives any necessary background information, improving the relevance of the response. It allows handling of single or multiple prompts, depending on user needs, and returns precise responses.

### When to Use It?

The LLMCaller node is ideal for scenarios like:

- Customer support inquiries
- Focused data extractions
- Automated workflows requiring single or batch AI responses
- Any task where precise output is needed from specific prompts and context

<Info>
  Providing the appropriate `prompt` and `context` together enhances the
  relevance and accuracy of the AIâ€™s responses.
</Info>
